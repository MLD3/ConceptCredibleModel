This repository contains code to replicate experiments in the 2022 NeurIPS paper, "Learning Concept Credible Models for Mitigating Shortcuts".

Given access to a representation based on domain knowledge (i.e. known concepts), we want to learn a model that is accurate regardless of whether the training data is biased (i.e., containing shortcuts that do not hold in practice) and whether the known concepts alone are sufficient for accurate predictions. We call such a model a concept credible model (CCM). To achieve that end, we proposed 2 methods, CCM EYE and CCM RES, that is provably concept credible in some linear settings and can empirically mitigate learning shortcuts even when assumptions are broken. 

The code directories are organized as the following

~mimic_scripts/~ contains the training code for reproducing experiments on MIMIC-CXR dataset.
~scripts/~ contains the training code for reproducing experiments on CUB birds dataset.
~notebooks/~ contains ipython notebook for visualization of the results.

Here is an example of running the baseline models on the CUB dataset:

For CBM
#+BEGIN_SRC bash
"TODO"
#+END_SRC

For CCM RES
#+BEGIN_SRC bash
"TODO"
#+END_SRC

For CCM EYE
#+BEGIN_SRC bash
"TODO"
#+END_SRC

For STD(X)
#+BEGIN_SRC bash
"TODO"
#+END_SRC

For STD(C, X)
#+BEGIN_SRC bash
"TODO"
#+END_SRC
